{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"hlV_n6YuNDW0aSNoNAyQCg\",\n",
    "    client_secret=\"O0K6QBLt3_Uo1yKQSxoUAYHpEm2BGw\",\n",
    "    user_agent=\"ThisIsYoosh \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_data(search_query, subreddit_name, post_num, comment_num):\n",
    "    subreddit = {}\n",
    "    title = {}\n",
    "    flair = {}\n",
    "    date = {}\n",
    "    body = {}\n",
    "    comments = {}\n",
    "    i = 1\n",
    "    search_results = reddit.subreddit(subreddit_name).search(search_query, sort=\"relevance\", limit=post_num)\n",
    "    for submission in search_results:\n",
    "        subreddit[i] = submission.subreddit.display_name\n",
    "        title[i] = submission.title\n",
    "        flair[i] = submission.link_flair_text\n",
    "        date[i] = datetime.datetime.utcfromtimestamp(submission.created_utc).strftime('%d/%m/%Y %H:%M:%S')\n",
    "        body[i] = submission.selftext\n",
    "        top_comments = submission.comments.list()[:comment_num]\n",
    "        ci = []\n",
    "        for comment in top_comments:\n",
    "            ci.append(comment.body)\n",
    "        comments[i] = ci\n",
    "        i+=1\n",
    "    return subreddit, title, flair, date, body, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits = {}\n",
    "general_titles = {}\n",
    "general_flairs = {}\n",
    "general_dates = {}\n",
    "general_bodies = {}\n",
    "general_comments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"soccer\"], general_titles[\"soccer\"], general_flairs[\"soccer\"], general_dates[\"soccer\"], general_bodies[\"soccer\"], general_comments[\"soccer\"] = get_reddit_data(\"VAR error\", \"soccer\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"soccer\"], general_titles[\"soccer\"], general_flairs[\"soccer\"], general_dates[\"soccer\"], general_bodies[\"soccer\"], general_comments[\"soccer\"] = get_reddit_data(\"VAR\", \"soccer\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(general_subreddits, file)\n",
    "file.close()\n",
    "with open('general titles.pkl', 'wb') as file:\n",
    "    pickle.dump(general_titles, file)\n",
    "file.close()\n",
    "with open('general flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(general_flairs, file)\n",
    "file.close()\n",
    "with open('general dates.pkl', 'wb') as file:\n",
    "    pickle.dump(general_dates, file)\n",
    "file.close()\n",
    "with open('general bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(general_bodies, file)\n",
    "file.close()\n",
    "with open('general comments.pkl', 'wb') as file:\n",
    "    pickle.dump(general_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"football\"], general_titles[\"football\"], general_flairs[\"football\"], general_dates[\"football\"], general_bodies[\"football\"], general_comments[\"football\"] = get_reddit_data(\"VAR\", \"football\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"football\"], general_titles[\"football\"], general_flairs[\"football\"], general_dates[\"football\"], general_bodies[\"football\"], general_comments[\"football\"] = get_reddit_data(\"VAR error\", \"football\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(general_subreddits, file)\n",
    "file.close()\n",
    "with open('general titles.pkl', 'wb') as file:\n",
    "    pickle.dump(general_titles, file)\n",
    "file.close()\n",
    "with open('general flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(general_flairs, file)\n",
    "file.close()\n",
    "with open('general dates.pkl', 'wb') as file:\n",
    "    pickle.dump(general_dates, file)\n",
    "file.close()\n",
    "with open('general bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(general_bodies, file)\n",
    "file.close()\n",
    "with open('general comments.pkl', 'wb') as file:\n",
    "    pickle.dump(general_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"PremierLeague\"], general_titles[\"PremierLeague\"], general_flairs[\"PremierLeague\"], general_dates[\"PremierLeague\"], general_bodies[\"PremierLeague\"], general_comments[\"PremierLeague\"] = get_reddit_data(\"VAR\", \"PremierLeague\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"PremierLeague\"], general_titles[\"PremierLeague\"], general_flairs[\"PremierLeague\"], general_dates[\"PremierLeague\"], general_bodies[\"PremierLeague\"], general_comments[\"PremierLeague\"] = get_reddit_data(\"VAR error\", \"PremierLeague\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(general_subreddits, file)\n",
    "file.close()\n",
    "with open('general titles.pkl', 'wb') as file:\n",
    "    pickle.dump(general_titles, file)\n",
    "file.close()\n",
    "with open('general flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(general_flairs, file)\n",
    "file.close()\n",
    "with open('general dates.pkl', 'wb') as file:\n",
    "    pickle.dump(general_dates, file)\n",
    "file.close()\n",
    "with open('general bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(general_bodies, file)\n",
    "file.close()\n",
    "with open('general comments.pkl', 'wb') as file:\n",
    "    pickle.dump(general_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"worldcup\"], general_titles[\"worldcup\"], general_flairs[\"worldcup\"], general_dates[\"worldcup\"], general_bodies[\"worldcup\"], general_comments[\"worldcup\"] = get_reddit_data(\"VAR\", \"worldcup\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"worldcup\"], general_titles[\"worldcup\"], general_flairs[\"worldcup\"], general_dates[\"worldcup\"], general_bodies[\"worldcup\"], general_comments[\"worldcup\"] = get_reddit_data(\"VAR error\", \"worldcup\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(general_subreddits, file)\n",
    "file.close()\n",
    "with open('general titles.pkl', 'wb') as file:\n",
    "    pickle.dump(general_titles, file)\n",
    "file.close()\n",
    "with open('general flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(general_flairs, file)\n",
    "file.close()\n",
    "with open('general dates.pkl', 'wb') as file:\n",
    "    pickle.dump(general_dates, file)\n",
    "file.close()\n",
    "with open('general bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(general_bodies, file)\n",
    "file.close()\n",
    "with open('general comments.pkl', 'wb') as file:\n",
    "    pickle.dump(general_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"MLS\"], general_titles[\"MLS\"], general_flairs[\"MLS\"], general_dates[\"MLS\"], general_bodies[\"MLS\"], general_comments[\"MLS\"] = get_reddit_data(\"VAR\", \"MLS\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"MLS\"], general_titles[\"MLS\"], general_flairs[\"MLS\"], general_dates[\"MLS\"], general_bodies[\"MLS\"], general_comments[\"MLS\"] = get_reddit_data(\"VAR error\", \"MLS\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(general_subreddits, file)\n",
    "file.close()\n",
    "with open('general titles.pkl', 'wb') as file:\n",
    "    pickle.dump(general_titles, file)\n",
    "file.close()\n",
    "with open('general flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(general_flairs, file)\n",
    "file.close()\n",
    "with open('general dates.pkl', 'wb') as file:\n",
    "    pickle.dump(general_dates, file)\n",
    "file.close()\n",
    "with open('general bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(general_bodies, file)\n",
    "file.close()\n",
    "with open('general comments.pkl', 'wb') as file:\n",
    "    pickle.dump(general_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"LaLiga\"], general_titles[\"LaLiga\"], general_flairs[\"LaLiga\"], general_dates[\"LaLiga\"], general_bodies[\"LaLiga\"], general_comments[\"LaLiga\"] = get_reddit_data(\"VAR\", \"LaLiga\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_subreddits[\"LaLiga\"], general_titles[\"LaLiga\"], general_flairs[\"LaLiga\"], general_dates[\"LaLiga\"], general_bodies[\"LaLiga\"], general_comments[\"LaLiga\"] = get_reddit_data(\"VAR error\", \"LaLiga\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('general subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(general_subreddits, file)\n",
    "file.close()\n",
    "with open('general titles.pkl', 'wb') as file:\n",
    "    pickle.dump(general_titles, file)\n",
    "file.close()\n",
    "with open('general flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(general_flairs, file)\n",
    "file.close()\n",
    "with open('general dates.pkl', 'wb') as file:\n",
    "    pickle.dump(general_dates, file)\n",
    "file.close()\n",
    "with open('general bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(general_bodies, file)\n",
    "file.close()\n",
    "with open('general comments.pkl', 'wb') as file:\n",
    "    pickle.dump(general_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits = {}\n",
    "other_titles = {}\n",
    "other_flairs = {}\n",
    "other_dates = {}\n",
    "other_bodies = {}\n",
    "other_comments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits[\"ARSvsBRE\"], other_titles[\"ARSvsBRE\"], other_flairs[\"ARSvsBRE\"], other_dates[\"ARSvsBRE\"], other_bodies[\"ARSvsBRE\"], other_comments[\"ARSvsBRE\"] = get_reddit_data(\"Arsenal vs Brentford VAR error\", \"all\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('other subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(other_subreddits, file)\n",
    "file.close()\n",
    "with open('other titles.pkl', 'wb') as file:\n",
    "    pickle.dump(other_titles, file)\n",
    "file.close()\n",
    "with open('other flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(other_flairs, file)\n",
    "file.close()\n",
    "with open('other dates.pkl', 'wb') as file:\n",
    "    pickle.dump(other_dates, file)\n",
    "file.close()\n",
    "with open('other bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(other_bodies, file)\n",
    "file.close()\n",
    "with open('other comments.pkl', 'wb') as file:\n",
    "    pickle.dump(other_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits[\"WHUvsCHE\"], other_titles[\"WHUvsCHE\"], other_flairs[\"WHUvsCHE\"], other_dates[\"WHUvsCHE\"], other_bodies[\"WHUvsCHE\"], other_comments[\"WHUvsCHE\"] = get_reddit_data(\"West Ham United vs Chelsea VAR error\", \"all\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('other subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(other_subreddits, file)\n",
    "file.close()\n",
    "with open('other titles.pkl', 'wb') as file:\n",
    "    pickle.dump(other_titles, file)\n",
    "file.close()\n",
    "with open('other flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(other_flairs, file)\n",
    "file.close()\n",
    "with open('other dates.pkl', 'wb') as file:\n",
    "    pickle.dump(other_dates, file)\n",
    "file.close()\n",
    "with open('other bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(other_bodies, file)\n",
    "file.close()\n",
    "with open('other comments.pkl', 'wb') as file:\n",
    "    pickle.dump(other_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits[\"MCIvsSOU\"], other_titles[\"MCIvsSOU\"], other_flairs[\"MCIvsSOU\"], other_dates[\"MCIvsSOU\"], other_bodies[\"MCIvsSOU\"], other_comments[\"MCIvsSOU\"] = get_reddit_data(\"Manchester City vs Southampton VAR error\", \"all\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('other subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(other_subreddits, file)\n",
    "file.close()\n",
    "with open('other titles.pkl', 'wb') as file:\n",
    "    pickle.dump(other_titles, file)\n",
    "file.close()\n",
    "with open('other flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(other_flairs, file)\n",
    "file.close()\n",
    "with open('other dates.pkl', 'wb') as file:\n",
    "    pickle.dump(other_dates, file)\n",
    "file.close()\n",
    "with open('other bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(other_bodies, file)\n",
    "file.close()\n",
    "with open('other comments.pkl', 'wb') as file:\n",
    "    pickle.dump(other_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits[\"TOTvsNEW\"], other_titles[\"TOTvsNEW\"], other_flairs[\"TOTvsNEW\"], other_dates[\"TOTvsNEW\"], other_bodies[\"TOTvsNEW\"], other_comments[\"TOTvsNEW\"] = get_reddit_data(\"Tottenham Hotspur vs Newcastle United VAR error\", \"all\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('other subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(other_subreddits, file)\n",
    "file.close()\n",
    "with open('other titles.pkl', 'wb') as file:\n",
    "    pickle.dump(other_titles, file)\n",
    "file.close()\n",
    "with open('other flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(other_flairs, file)\n",
    "file.close()\n",
    "with open('other dates.pkl', 'wb') as file:\n",
    "    pickle.dump(other_dates, file)\n",
    "file.close()\n",
    "with open('other bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(other_bodies, file)\n",
    "file.close()\n",
    "with open('other comments.pkl', 'wb') as file:\n",
    "    pickle.dump(other_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits[\"IRNvsPOR\"], other_titles[\"IRNvsPOR\"], other_flairs[\"IRNvsPOR\"], other_dates[\"IRNvsPOR\"], other_bodies[\"IRNvsPOR\"], other_comments[\"IRNvsPOR\"] = get_reddit_data(\"Iran vs Portugal VAR error\", \"all\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('other subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(other_subreddits, file)\n",
    "file.close()\n",
    "with open('other titles.pkl', 'wb') as file:\n",
    "    pickle.dump(other_titles, file)\n",
    "file.close()\n",
    "with open('other flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(other_flairs, file)\n",
    "file.close()\n",
    "with open('other dates.pkl', 'wb') as file:\n",
    "    pickle.dump(other_dates, file)\n",
    "file.close()\n",
    "with open('other bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(other_bodies, file)\n",
    "file.close()\n",
    "with open('other comments.pkl', 'wb') as file:\n",
    "    pickle.dump(other_comments, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_subreddits[\"TOTvsLIV\"], other_titles[\"TOTvsLIV\"], other_flairs[\"TOTvsLIV\"], other_dates[\"TOTvsLIV\"], other_bodies[\"TOTvsLIV\"], other_comments[\"TOTvsLIV\"] = get_reddit_data(\"Tottenham Hotspur vs Liverpool VAR error\", \"all\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('other subreddits.pkl', 'wb') as file:\n",
    "    pickle.dump(other_subreddits, file)\n",
    "file.close()\n",
    "with open('other titles.pkl', 'wb') as file:\n",
    "    pickle.dump(other_titles, file)\n",
    "file.close()\n",
    "with open('other flairs.pkl', 'wb') as file:\n",
    "    pickle.dump(other_flairs, file)\n",
    "file.close()\n",
    "with open('other dates.pkl', 'wb') as file:\n",
    "    pickle.dump(other_dates, file)\n",
    "file.close()\n",
    "with open('other bodies.pkl', 'wb') as file:\n",
    "    pickle.dump(other_bodies, file)\n",
    "file.close()\n",
    "with open('other comments.pkl', 'wb') as file:\n",
    "    pickle.dump(other_comments, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
